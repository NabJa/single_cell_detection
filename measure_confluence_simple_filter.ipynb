{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, basename\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import setp\n",
    "import matplotlib.colors as mcolors\n",
    "import cv2\n",
    "from time import time\n",
    "\n",
    "from data import bbox_utils as box\n",
    "from statistics import evaluate_distance_cutoffs\n",
    "from visualization import write_text_on_image, mask_color_img\n",
    "\n",
    "from prediction import simple_confluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIRS = glob(\"D:\\\\Nabil_object_detection\\\\train\\\\data\\\\*\")\n",
    "BASE_DIRS = [join(d, \"10x\") for d in BASE_DIRS]\n",
    "BASE_DIRS.append(\"D:\\\\Nabil_object_detection\\\\val\\\\20200204_NRK_Hoechst_Pos7\\\\10x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"D:\\\\Nabil_object_detection\\\\val\\\\20200204_NRK_Hoechst_Pos7\\\\10x\"\n",
    "out_path = \"C:\\\\Users\\\\N.Jabareen\\\\presentations\\\\simple_conflunce_prediction\"\n",
    "images = tqdm(glob(join(path, \"*.png\")))\n",
    "for i, image_path in enumerate(images):\n",
    "    image = cv2.imread(image_path)\n",
    "    segmented = simple_segement(image)\n",
    "    masked = mask_color_img(image, segmented)\n",
    "    confluence = get_confluency(segmented)*100\n",
    "    masked = cv2.putText(masked, f\"Confluence: {confluence:.2f}%\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                   3, (255,255,255), 7, cv2.LINE_AA) \n",
    "    masked = cv2.putText(masked, f\"Frame: {i}\", (50, 900), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                   2, (255,255,255), 7, cv2.LINE_AA) \n",
    "    \n",
    "#     plt.imshow(masked)\n",
    "#     plt.show()    \n",
    "    cv2.imwrite(join(out_path, f\"image_{i}.png\"), masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for image_dir in BASE_DIRS:\n",
    "    image_paths = glob(join(image_dir, \"*.png\"))\n",
    "    \n",
    "    first_image, last_image = cv2.imread(image_paths[0]), cv2.imread(image_paths[-1])\n",
    "    first_segments, last_segments = simple_segement(first_image), simple_segement(last_image)\n",
    "    first_masked, last_masked = mask_color_img(first_image, first_segments), mask_color_img(last_image, last_segments)\n",
    "    \n",
    "    fist_conf, last_conf = get_confluency(first_segments)*100, get_confluency(last_segments)*100\n",
    "    \n",
    "    dir_name = image_dir.split(\"\\\\\")[-2]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, constrained_layout=True)\n",
    "    fig.suptitle(f\"{dir_name}\", fontsize=20, y=0.75)\n",
    "    fig.set_size_inches((15,15))\n",
    "    \n",
    "    axs[0].set_title(f\"First image, confluence={fist_conf:.2f}%\", fontsize=15)\n",
    "    axs[0].imshow(first_masked, cmap=\"gray\")\n",
    "    axs[1].set_title(f\"Last image, confluence={last_conf:.2f}%\", fontsize=15)\n",
    "    axs[1].imshow(last_masked, cmap=\"gray\")\n",
    "    \n",
    "    fig.set_tight_layout(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confluencys = {}\n",
    "stds = {}\n",
    "for image_dir in BASE_DIRS:\n",
    "    \n",
    "    dir_name = image_dir.split(\"\\\\\")[-2]\n",
    "    \n",
    "    confl, std = get_image_stats(image_dir, normalize=False)\n",
    "    \n",
    "    confluencys[dir_name] = confl\n",
    "    stds[dir_name] = std\n",
    "    \n",
    "#     max_measure = max(max(confl), max(stds))\n",
    "   \n",
    "#     plt.figure(figsize=(12,6))\n",
    "#     plt.title(f\"{dir_name}\", fontsize=20)\n",
    "#     plt.plot(confl, label=\"Confluency\", linewidth=5)\n",
    "#     plt.plot(stds, label=\"Normalized Standard deviation\")\n",
    "#     plt.xlabel(\"Image\", fontsize=15)\n",
    "#     plt.ylabel(\"Confluency\", fontsize=15) \n",
    "#     plt.xticks(fontsize=10) \n",
    "#     plt.yticks(np.linspace(0, max_measure, num=5), fontsize=10) \n",
    "#     plt.legend(fontsize=15, loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Confluence in validation image\", fontsize=25)\n",
    "plt.plot(confluencys[\"20200204_NRK_Hoechst_Pos7\"], linewidth=5, color=\"blue\")\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Frame\", fontsize=20)\n",
    "plt.ylabel(\"Confluence in %\", fontsize=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_two_axis(stds[\"20200204_NRK_Hoechst_Pos7\"], confluencys[\"20200204_NRK_Hoechst_Pos7\"], \"Validation Image\", \"Standard deviation\", \"Confluence in %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(confluencys[\"20200204_NRK_Hoechst_Pos7\"], linewidth=4)\n",
    "plt.plot(stds[\"20200204_NRK_Hoechst_Pos7\"], linewidth=4)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Frame\", fontsize=20)\n",
    "plt.ylabel(\"Confluence in %\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Confluence of annotated experiments\", fontsize=25)\n",
    "for key, item in confluencys.items():\n",
    "    alpha = 1\n",
    "    if \"Pos8\" in key or \"NRK\" in key:\n",
    "        alpha = 0.2\n",
    "    plt.plot(item, label=key, linewidth=4, alpha=alpha)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Frame\", fontsize=20)\n",
    "plt.ylabel(\"Confluence in %\", fontsize=20)\n",
    "plt.legend(fontsize=20, loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC vs. Confluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, average_precision_score\n",
    "\n",
    "from data import tf_record_loading as loader\n",
    "from data import bbox_utils as box\n",
    "from prediction import prediction_utils\n",
    "import statistics\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATHS = {\n",
    "    \"SSD_BF\": \"D:\\\\Nabil_object_detection\\\\models\\\\graph_imgSize_vs_bboxSize\\\\ssd_resnet50_v1_fpn_10x_tiles0_bboxes40\",\n",
    "    \"SSD_LF\": \"D:\\\\Nabil_object_detection\\\\models\\\\graph_imgSize_vs_bboxSize\\\\ssd_resnet50_v1_fpn_z00_tiles0_bboxes40\",\n",
    "    \"RCNN_BF\": \"D:\\\\Nabil_object_detection\\\\models\\\\graph_imgSize_vs_bboxSize\\\\faster_rcnn_resnet101_coco_10x_tiles0_bboxes40\",\n",
    "    \"RCNN_LF\": \"D:\\\\Nabil_object_detection\\\\models\\\\graph_imgSize_vs_bboxSize\\\\faster_rcnn_resnet101_coco_z00_tiles0_bboxes40\",\n",
    "}\n",
    "\n",
    "DATA_PATHS = {\n",
    "    \"BF\": \"D:\\\\Nabil_object_detection\\\\val\\\\10x_tiles0_bboxes40.tfrecord\",\n",
    "    \"LF\": \"D:\\\\Nabil_object_detection\\\\val\\\\z00_tiles0_bboxes40.tfrecord\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_length(path):\n",
    "    data = loader.tf_dataset_generator(path)\n",
    "    return len([_ for _ in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_model_perfomance(model_path, data_path):\n",
    "    \n",
    "    data_length = get_generator_length(data_path)\n",
    "    data = loader.tf_dataset_generator(data_path)\n",
    "    model = prediction_utils.load_model(model_path)\n",
    "    \n",
    "    aucs = []\n",
    "    mAPs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    knn_stats = []\n",
    "    \n",
    "    print(f\"Predicting with: {basename(model_path)}\")\n",
    "    \n",
    "    for i, annotation in enumerate(data):\n",
    "        \n",
    "        print(f\"\\t Image {i+1}/{data_length}\", end=\"\\r\")\n",
    "        \n",
    "        image = annotation.get(\"image\")\n",
    "        gt_bbox = annotation.get(\"bboxes\")\n",
    "\n",
    "        prediction = prediction_utils.run_inference_for_single_image(model, image)\n",
    "        pred_boxes = prediction.get(\"detection_boxes\")\n",
    "        pred_scores = prediction.get(\"detection_scores\")\n",
    "\n",
    "        mAP, precision, recall, _ = statistics.compute_ap(pred_boxes, gt_bbox)\n",
    "        \n",
    "        # Precision, recall on knn\n",
    "        distance_thresholds = np.linspace(40, 130, 5)\n",
    "               \n",
    "        knn_stat = evaluate_distance_cutoffs(pred_boxes, gt_bbox, distance_thresholds)\n",
    "        knn_stats.append(knn_stat)\n",
    "        \n",
    "        aucs.append(auc(recall, precision))\n",
    "        mAPs.append(mAP)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    return {\"map\": mAPs, \"auc\": aucs, \"precision\": precisions, \"recall\": recalls, \"knn\": knn_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfomances = {}\n",
    "for model_key in MODEL_PATHS.keys():\n",
    "    data_key = \"BF\" if \"BF\" in model_key else \"LF\"\n",
    "    \n",
    "    tic = time()\n",
    "    perfomance = measure_model_perfomance(MODEL_PATHS[model_key], DATA_PATHS[data_key])\n",
    "    tac = time()\n",
    "    \n",
    "    print(f\"Finished in {tac-tic:.2f} seconds\\n\")\n",
    "    \n",
    "    perfomances[model_key] = perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(perfomances, open(\"perfomances.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knn_boxplot(perfomances):\n",
    "    \n",
    "    def setBoxColors(bp):\n",
    "        colors = list(mcolors.TABLEAU_COLORS.values())[:4]\n",
    "\n",
    "        setp(bp['boxes'][0], color=colors[0], lw=4)\n",
    "        setp(bp['caps'][0], color=colors[0], lw=4)\n",
    "        setp(bp['caps'][1], color=colors[0], lw=4)\n",
    "        setp(bp['whiskers'][0], color=colors[0], lw=4)\n",
    "        setp(bp['whiskers'][1], color=colors[0], lw=4)\n",
    "        setp(bp['medians'][0], color=colors[0], lw=4)\n",
    "\n",
    "        setp(bp['boxes'][1], color=colors[1], lw=4)\n",
    "        setp(bp['caps'][2], color=colors[1], lw=4)\n",
    "        setp(bp['caps'][3], color=colors[1], lw=4)\n",
    "        setp(bp['whiskers'][2], color=colors[1], lw=4)\n",
    "        setp(bp['whiskers'][3], color=colors[1], lw=4)\n",
    "        setp(bp['medians'][1], color=colors[1], lw=4)\n",
    "\n",
    "        setp(bp['boxes'][2], color=colors[2], lw=4)\n",
    "        setp(bp['caps'][4], color=colors[2], lw=4)\n",
    "        setp(bp['caps'][5], color=colors[2], lw=4)\n",
    "        setp(bp['whiskers'][4], color=colors[2], lw=4)\n",
    "        setp(bp['whiskers'][5], color=colors[2], lw=4)\n",
    "        setp(bp['medians'][2], color=colors[2], lw=4)\n",
    "\n",
    "        setp(bp['boxes'][3], color=colors[3], lw=4)\n",
    "        setp(bp['caps'][6], color=colors[3], lw=4)\n",
    "        setp(bp['caps'][7], color=colors[3], lw=4)\n",
    "        setp(bp['whiskers'][6], color=colors[3], lw=4)\n",
    "        setp(bp['whiskers'][7], color=colors[3], lw=4)\n",
    "        setp(bp['medians'][3], color=colors[3], lw=4)\n",
    "\n",
    "    def get_auc_from_knn(knn):\n",
    "        precisions = knn.get(\"precisions\")\n",
    "        recalls = knn.get(\"recalls\")\n",
    "        aucs = [auc(r, p) for r, p in zip(precisions, recalls)]\n",
    "        return aucs\n",
    "    \n",
    "    model_perfomances = {k: [] for k in perfomances.keys()}\n",
    "\n",
    "    for i in range(75):\n",
    "        for model, metric in perfomances.items():\n",
    "            aucs = get_auc_from_knn(metric.get(\"knn\")[i])\n",
    "            model_perfomances[model].append(aucs)\n",
    "\n",
    "    aucs = np.array([np.array(value).reshape(5, 75) for value in model_perfomances.values()])\n",
    "    \n",
    "    initial_pos = np.array([1, 2, 3, 4])\n",
    "    max_pos = 0\n",
    "    model_id = initial_pos.tolist() * 5\n",
    "    distance_thresholds = np.linspace(40, 130, 5)\n",
    "\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title(\"Perfomance on distance thresholds\", fontsize=25)\n",
    "    for d_cutoff in range(aucs.shape[1]):\n",
    "        positions = initial_pos + max_pos + 2\n",
    "        max_pos = np.max(positions)\n",
    "\n",
    "        box_data = aucs[:, d_cutoff, :].tolist()\n",
    "\n",
    "        box = plt.boxplot(box_data, positions=positions)\n",
    "        box = setBoxColors(box)\n",
    "    \n",
    "    plt.xticks(ticks=[4.5, 10.5, 16.5, 22.5, 28.5], labels=distance_thresholds, fontsize=20)\n",
    "    plt.yticks(np.linspace(0, 1, 6), fontsize=20)\n",
    "    plt.ylabel(\"AUC\", fontsize=20)\n",
    "    plt.xlabel(\"Distance cutoff\", fontsize=20)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_knn_boxplot(perfomances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perfomances = {k: [] for k in perfomances.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_from_knn(knn):\n",
    "    precisions = knn.get(\"precisions\")\n",
    "    recalls = knn.get(\"recalls\")\n",
    "    aucs = [auc(r, p) for r, p in zip(precisions, recalls)]\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(75):\n",
    "    for model, metric in perfomances.items():\n",
    "        aucs = get_auc_from_knn(metric.get(\"knn\")[i])\n",
    "        model_perfomances[model].append(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(model_perfomances[\"SSD_LF\"]).reshape((5, 75))\n",
    "b = np.array(model_perfomances[\"SSD_BF\"]).reshape((5, 75))\n",
    "c = np.array(model_perfomances[\"RCNN_LF\"]).reshape((5, 75))\n",
    "d = np.array(model_perfomances[\"RCNN_BF\"]).reshape((5, 75))\n",
    "\n",
    "x = [a,b,c,d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Model Perfomance\", fontsize=25)\n",
    "for k, m in enumerate(x):\n",
    "    for i in range(m.shape[0]):\n",
    "        colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "        box = plt.boxplot(m[i], positions=[k+i], widths=0.5)\n",
    "        for box_property in box.values():\n",
    "            setp(box_property, color=colors[i], lw=4)\n",
    "\n",
    "plt.xticks(ticks=[0,1,2,3], labels=[model for model in perfomances.keys()], fontsize=20)\n",
    "# plt.yticks(np.linspace(0.5, 1, 6), fontsize=20)\n",
    "plt.ylabel(\"AUC\", fontsize=20)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Model Perfomance\", fontsize=25)\n",
    "for i, (model, metric) in enumerate(perfomances.items()):\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "    box = plt.boxplot(metric.get(\"auc\"), positions=[i], widths=0.5)\n",
    "    for box_property in box.values():\n",
    "        setp(box_property, color=colors[i], lw=4)\n",
    "        \n",
    "\n",
    "plt.xticks(ticks=[0,1,2,3], labels=[model for model in perfomances.keys()], fontsize=20)\n",
    "plt.yticks(np.linspace(0.5, 1, 6), fontsize=20)\n",
    "plt.ylabel(\"AUC\", fontsize=20)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_path = join(path, \"precision_recall_curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(75):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title(f\"Model Perfomance, Frame={i+1}\", fontsize=25)\n",
    "    for model, metrics in perfomances.items():\n",
    "        plt.plot(metrics.get(\"recall\")[i], metrics.get(\"precision\")[i], label=model, linewidth=4)\n",
    "    plt.xticks(np.linspace(0, 1, 11), fontsize=15)\n",
    "    plt.yticks(np.linspace(0, 1, 11), fontsize=15)\n",
    "    plt.xlabel(\"Recall\", fontsize=20)\n",
    "    plt.ylabel(\"Precision\", fontsize=20)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=25)\n",
    "    plt.savefig(join(prec_path, f\"curve_{i+1}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model, metrics in perfomances.items():\n",
    "    print(model)\n",
    "    for recall, precision in zip(metrics.get(\"recall\"), metrics.get(\"precision\")):\n",
    "        print(recall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Model Perfomance\", fontsize=25)\n",
    "for model, metrics in perfomances.items():\n",
    "    plt.plot(metrics.get(\"auc\"), linewidth=4, label=model)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylim((0.5, 1))\n",
    "plt.xlabel(\"Frame\", fontsize=20)\n",
    "plt.ylabel(\"AUC\", fontsize=20)\n",
    "plt.grid()\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Model Perfomance\", fontsize=25)\n",
    "for model, metric in perfomances.items():\n",
    "    plt.scatter(confluencys.get(\"20200204_NRK_Hoechst_Pos7\"), metric.get(\"auc\"), s=100, label=model, alpha=0.8)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylim((0.5, 1))\n",
    "plt.xlabel(\"Conflunce\", fontsize=20)\n",
    "plt.ylabel(\"AUC\", fontsize=20)\n",
    "plt.legend(fontsize=20, loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_two_axis([metrics.get(\"auc\") for metrics in perfomances.values()],\n",
    "                   [confluencys.get(\"20200204_NRK_Hoechst_Pos7\")],\n",
    "                  \"Model Perfomance\", \"AUC\", \"Confluence in %\",\n",
    "                  labels1=[key for key in perfomances.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_two_axis(y1, y2, title=\"\", ylabel1=\"\", ylabel2=\"\", xlabel=\"\", labels1=None):\n",
    "    \n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "    idx = 0\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    fig.suptitle(title, fontsize=25)\n",
    "    fig.set_size_inches((16, 8))\n",
    "    \n",
    "    for data, label in zip(y1, labels1):\n",
    "        ax1.plot(data, linewidth=4, color=colors[idx], label=label)\n",
    "        idx += 1\n",
    "    \n",
    "    ax1.set_ylabel(ylabel1, fontsize=25)\n",
    "    ax1.yaxis.label.set_color(\"black\")\n",
    "    ax1.tick_params(labelsize=15)\n",
    "    ax1.set_xlabel(xlabel, fontsize=25)\n",
    "    ax1.grid(axis=\"both\")\n",
    "    ax1.set_ylim((0.5, 1))\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    for data in y2:\n",
    "        ax2.plot(data, linewidth=4, color=\"blue\")\n",
    "        idx += 1\n",
    "    ax2.set_ylabel(ylabel2, fontsize=25)\n",
    "    ax2.yaxis.label.set_color(\"blue\")\n",
    "    ax2.tick_params(labelsize=15)\n",
    "    \n",
    "    ax1.legend(loc=\"lower right\", fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = []\n",
    "mAPs = []\n",
    "\n",
    "for annotation in tqdm(data, total=75):\n",
    "    image = annotation.get(\"image\")\n",
    "    gt_bbox = annotation.get(\"bboxes\")\n",
    "    \n",
    "    prediction = prediction_utils.run_inference_for_single_image(model, image)\n",
    "    pred_boxes = prediction.get(\"detection_boxes\")\n",
    "    pred_scores = prediction.get(\"detection_scores\")\n",
    "    \n",
    "    mAP, precisions, recalls, _ = statistics.compute_ap(pred_boxes, gt_bbox)\n",
    "    \n",
    "    aucs.append(auc(recalls, precisions))\n",
    "    mAPs.append(mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.tf_dataset_generator(DATA_PATH)\n",
    "a = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.tf_dataset_generator(DATA_PATH)\n",
    "\n",
    "image_means = []\n",
    "image_stds = []\n",
    "confluences = []\n",
    "cells = []\n",
    "\n",
    "for annotation in tqdm(data, total=75):\n",
    "    image = annotation.get(\"image\")\n",
    "    \n",
    "    number_of_boxes = annotation.get(\"bboxes\").shape[0]\n",
    "    cells.append(number_of_boxes)\n",
    "    \n",
    "    image_means.append(np.mean(image))\n",
    "    image_stds.append(np.std(image))\n",
    "    \n",
    "    segmented = simple_segement(image)\n",
    "    confl = get_confluency(segmented)\n",
    "    confluences.append(confl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_two_axis(y1, y2, title=\"\", ylabel1=\"\", ylabel2=\"\", xlabel=\"Image\"):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    fig.suptitle(title, fontsize=25)\n",
    "    fig.set_size_inches((15, 9))\n",
    "\n",
    "    ax1.plot(y1, color=\"red\", linewidth=4)\n",
    "    ax1.set_ylabel(ylabel1, fontsize=25)\n",
    "    ax1.yaxis.label.set_color(\"red\")\n",
    "    ax1.tick_params(labelsize=15)\n",
    "    ax1.set_xlabel(xlabel, fontsize=25)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(y2, color=\"blue\", linewidth=4)\n",
    "    ax2.set_ylabel(ylabel2, fontsize=25)\n",
    "    ax2.yaxis.label.set_color(\"blue\")\n",
    "    ax2.tick_params(labelsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_two_axis(cells, confluencys, \"#Cells vs. Confluence\", \"Number of cells\", \"Confluence in %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_two_axis(image_stds, confluencys, \"Image Std. vs. Conflunce\", \"Image Std.\", \"Confluence in %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_two_axis(image_means, confluencys, \"Image Mean vs. Conflunce\", \"Image mean\", \"Confluence in %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_two_axis(aucs, confluencys, \"AUC and Confluence\", \"AUC\", \"Confluence in %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_two_axis(aucs, image_means, \"AUC vs. Image Mean\", \"AUC\", \"Image Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = []\n",
    "for i in range(1, len(confluencys)-1):\n",
    "    before, actual, after = confluencys[i-1], confluencys[i], confluencys[i+1]\n",
    "    \n",
    "    if before*0.98 > actual < after*0.98:\n",
    "        peaks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_two_axis(y1, y2, title=\"\", ylabel1=\"\", ylabel2=\"\", xlabel=\"Image\"):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    fig.suptitle(title, fontsize=25)\n",
    "    fig.set_size_inches((15, 9))\n",
    "\n",
    "    ax1.plot(y1, color=\"red\", linewidth=3)\n",
    "    ax1.set_ylabel(ylabel1, fontsize=25)\n",
    "    ax1.yaxis.label.set_color(\"red\")\n",
    "    ax1.tick_params(labelsize=15)\n",
    "    ax1.set_xlabel(xlabel, fontsize=25)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(y2, color=\"blue\", linewidth=5)\n",
    "    ax2.set_ylabel(ylabel2, fontsize=25)\n",
    "    ax2.yaxis.label.set_color(\"blue\")\n",
    "    ax2.tick_params(labelsize=15)\n",
    "    \n",
    "    _, _, ymin, ymax = ax2.yaxis.axes.axis()\n",
    "    ax2.vlines(peaks, ymin, ymax, colors=\"blue\", linestyles=\"dashed\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_two_axis(aucs, confluencys, \"AUC and Confluence\", \"AUC\", \"Confluence in %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on basic corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.tf_dataset_generator(DATA_PATH)\n",
    "path = \"D:\\\\Nabil_object_detection\\\\val\\\\20200204_NRK_Hoechst_Pos7\\\\10x_corrected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_aucs = []\n",
    "corrected_mAPs = []\n",
    "\n",
    "corrected_images = glob(join(path, \"*.png\"))\n",
    "\n",
    "for i, annotation in enumerate(tqdm(data, total=75)):\n",
    "\n",
    "    image = cv2.imread(corrected_images[i])\n",
    "    \n",
    "    gt_bbox = annotation.get(\"bboxes\")\n",
    "    \n",
    "    prediction = prediction_utils.run_inference_for_single_image(model, image)\n",
    "    pred_boxes = prediction.get(\"detection_boxes\")\n",
    "    pred_scores = prediction.get(\"detection_scores\")\n",
    "    \n",
    "    mAP, precisions, recalls, _ = statistics.compute_ap(pred_boxes, gt_bbox)\n",
    "    \n",
    "    corrected_aucs.append(auc(recalls, precisions))\n",
    "    corrected_mAPs.append(mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(corrected_aucs, \"red\", linewidth=3)\n",
    "plt.plot(aucs, color=\"blue\", linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(data):\n",
    "    x = list(range(len(data)))\n",
    "\n",
    "    x_new = np.linspace(0, 12, 75)\n",
    "\n",
    "    a_BSpline = make_interp_spline(x, data)\n",
    "    return a_BSpline(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_inter = interpolate(aucs)\n",
    "corrected_inter = interpolate(corrected_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.title(\"BaSiC correction\", fontsize=25)\n",
    "plt.plot(aucs_inter, color=\"blue\", linewidth=5, label=\"Raw\")\n",
    "plt.plot(corrected_inter, color=\"red\", linewidth=5, label=\"BaSiC\")\n",
    "plt.plot(aucs, color=\"blue\", linewidth=2, alpha=0.7)\n",
    "plt.plot(corrected_aucs, color=\"red\", linewidth=2, alpha=0.7)\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Image\", fontsize=20)\n",
    "plt.ylabel(\"AUC\", fontsize=20)\n",
    "\n",
    "plt.legend(loc=\"upper left\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Path(\"D:\\\\Nabil_object_detection\\\\models\\\\graph_faster_rcnn_resnet50\\\\Evaluation\\\\faster_rcnn_resnet50_z00\\\\metrics.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open(a, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf_detection_api_cpu': conda)",
   "language": "python",
   "name": "python37664bittfdetectionapicpuconda00064aecf2284de5a2295c9eee0915f5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
